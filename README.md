<div align="center">
  <p align="center">
    üê¶ <a href="https://twitter.com/maximelabonne">Follow me on X</a> ‚Ä¢ 
    ü§ó <a href="https://huggingface.co/mlabonne">Hugging Face</a> ‚Ä¢ 
    üíª <a href="https://mlabonne.github.io/blog">Blog</a> ‚Ä¢ 
    üìô <a href="https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python">Hands-on GNN</a>
  </p>
</div>
<br/>

Hi, I'm a Machine Learning Scientist, Author, Blogger, and LLM hacker.

## üíº Projects

* [**The LLM Course**](https://github.com/mlabonne/llm-course): A popular curated list of resources to get into LLMs (>15k ‚≠ê).
* [**Hands-on GNNs**](https://github.com/mlabonne/llm-course): My book about graph neural networks published by Packt (all the code is open source).
* [**LLMOps Tools**](https://github.com/mlabonne/llm-autoeval): Automate LLM pipelines with Colab notebooks like [LLM AutoEval](https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing), [LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing), and [AutoGGUF](https://colab.research.google.com/drive/1P646NEg33BZy4BfLDNpTz0V0lwIU3CHu?usp=sharing).

## ü§ó Models

* [**Phixtral**](https://huggingface.co/mlabonne/phixtral-2x2_8): The first Mixture of Experts with phi-2 models.
* [**Beyonder**](https://huggingface.co/mlabonne/Beyonder-4x7B-v2): Mixture of Experts with four excellent fine-tuned Mistral-7b models.
* [**NeuralMarcoro14**](https://huggingface.co/mlabonne/NeuralMarcoro14-7B): My most powerful general-purpose 7B model (rank 1 on the Open LLM Leaderboard).
* [**NeuralHermes**](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B): A DPO fine-tuned version of OpenHermes (extremely cost-efficient).
